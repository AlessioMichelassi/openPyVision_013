= Capitolo 3: Tecniche di Contrasto e Frame Rate

== 3.8 - CONTRAST SPEED

Ovviamente, in soldoni vogliamo capire se le nostre operazioni di contrasto ci garantiscono di mantenere il frame rate e quale delle operazioni ci permette di ottenere il risultato che ci serve.

Possiamo provare a creare un metodo per il contrasto lineare simile a quello proposto da Brinkman che in alcuni casi può essere una soluzione rapida ed efficace, un metodo simile a quello che abbiamo creato usando la sigmoide e usando una gamma, visto che l'operazione, come abbiamo visto, è molto rapida. Possiamo inoltre implementare anche i due metodi per il contrasto automatico usando histogram e CLAHE.

[source, python]
----
import cv2
import numpy as np
import timeit

# Metodo 1: Modifica Lineare del Contrasto
def adjust_contrast_linear(image, alpha=1.5, beta=0):
    return cv2.convertScaleAbs(image, alpha=alpha, beta=beta)

# Metodo 2: Regolazione Gamma
def adjust_contrast_gamma(image, gamma=1.0):
    inv_gamma = 1.0 / gamma
    table = np.array([(i / 255.0) ** inv_gamma * 255 for i in range(256)]).astype(np.uint8)
    return cv2.LUT(image, table)

def clahe(image, clip_limit=2.0, tile_grid_size=(8, 8)):
    channels = cv2.split(image)
    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_grid_size)
    clahe_channels = [clahe.apply(channel) for channel in channels]
    return cv2.merge(clahe_channels)

def histogram_equalization(image):
    channels = cv2.split(image)
    eq_channels = [cv2.equalizeHist(channel) for channel in channels]
    return cv2.merge(eq_channels)

def add_text_to_image(image, text):
    font = cv2.FONT_HERSHEY_SIMPLEX
    font_scale = 1
    color = (255, 255, 255)
    thickness = 2
    position = (10, 50)
    return cv2.putText(image, text, position, font, font_scale, color, thickness, cv2.LINE_AA)

# Genera un'immagine di test
image = cv2.imread(r"\openPyVisionBook\openPyVisionBook\cap3\cap3_6\lena_std.tif")

# Crea immagini con testo
original_with_text = add_text_to_image(image.copy(), "Original")
linear_with_text = add_text_to_image(adjust_contrast_linear(image, alpha=1.5, beta=20).copy(), "Linear Contrast")
gamma_with_text = add_text_to_image(adjust_contrast_gamma(image, gamma=1.2).copy(), "Gamma Adjustment")
clahe_with_text = add_text_to_image(clahe(image).copy(), "CLAHE")
hist_eq_with_text = add_text_to_image(histogram_equalization(image).copy(), "Histogram Equalization")

# Crea un mosaico di immagini su due righe
first_row = np.hstack((original_with_text, linear_with_text, gamma_with_text))
second_row = np.hstack((original_with_text, clahe_with_text, hist_eq_with_text))
big_image = np.vstack((first_row, second_row))

# Visualizza i risultati
cv2.imshow("Contrast Adjustment", big_image)
linear_test = timeit.timeit(lambda: adjust_contrast_linear(image, alpha=1.5, beta=20), number=1000)
gamma_test = timeit.timeit(lambda: adjust_contrast_gamma(image, gamma=1.2), number=1000)
clahe_test = timeit.timeit(lambda: clahe(image), number=1000)
hist_eq_test = timeit.timeit(lambda: histogram_equalization(image), number=1000)

print(f"Linear Contrast Adjustment: {linear_test:.2f} seconds for 1000 iterations = {linear_test / 1000:.4f} ms per iteration")
print(f"Gamma Adjustment: {gamma_test:.2f} seconds for 1000 iterations = {gamma_test / 1000:.4f} ms per iteration")
print(f"CLAHE: {clahe_test:.2f} seconds for 1000 iterations = {clahe_test / 1000:.4f} ms per iteration")
print(f"Histogram Equalization: {hist_eq_test:.2f} seconds for 1000 iterations = {hist_eq_test / 1000:.4f} ms per iteration")
cv2.waitKey(0)
cv2.destroyAllWindows()
----

Linear Contrast Adjustment: 0.09 seconds for 1000 iterations = 0.0001 ms per iteration
Gamma Adjustment: 0.13 seconds for 1000 iterations = 0.0001 ms per iteration
CLAHE: 0.88 seconds for 1000 iterations = 0.0009 ms per iteration
Histogram Equalization: 0.73 seconds for 1000 iterations = 0.0007 ms per iteration

La buona notizia è che sono tutte operazioni velocissime, quella un po' meno buona, che però non è poi così cattiva, è che CLAHE e histogram usati in questo modo tendono a far virare i colori. Osservando i colori dell'immagine originale ci si accorge come in effetti l'immagine abbia una dominante rossa/magenta, però chiaramente potrebbe non essere l'operazione che vogliamo ottenere.

Per affrontare questo problema, possiamo applicare queste tecniche nel dominio YUV, che separa la luminanza (Y) dalle informazioni cromatiche (U e V). Questo approccio permette di migliorare il contrasto senza influire sui colori originali dell'immagine.

=== Metodo CLAHE YUV

Il metodo `clahe_yuv` applica il CLAHE (Contrast Limited Adaptive Histogram Equalization) solo al canale Y (luminanza) dell'immagine convertita in YUV. Il CLAHE viene utilizzato per migliorare il contrasto locale senza amplificare eccessivamente il rumore, limitando il contrasto massimo per evitare artefatti visivi.

* Conversione a YUV: L'immagine RGB viene convertita nello spazio colore YUV.
* CLAHE sul canale Y: Il CLAHE viene applicato solo al canale Y, che contiene le informazioni di luminanza.
* Riconversione a RGB: L'immagine modificata viene riconvertita nello spazio colore RGB.

Questo metodo mantiene i colori più naturali rispetto all'applicazione del CLAHE direttamente sui canali RGB, poiché l'operazione di contrasto non influisce sui canali U e V, che contengono le informazioni cromatiche.

=== Metodo Histogram Equalization YUV

Analogamente, il metodo `histogram_equalization_yuv` applica l'equalizzazione dell'istogramma al canale Y di un'immagine YUV. Questo processo redistribuisce i valori di luminanza in modo uniforme su tutta la gamma disponibile, migliorando il contrasto globale dell'immagine.

* Conversione a YUV: Come nel metodo CLAHE, l'immagine RGB viene prima convertita in YUV.
* Equalizzazione sul canale Y: L'equalizzazione dell'istogramma viene applicata solo al canale Y, migliorando il contrasto senza influire sui colori.
* Riconversione a RGB: L'immagine modificata viene quindi riconvertita nello spazio colore RGB.

[source, python]
----
import cv2
import numpy as np
import timeit

# Metodo 1: Modifica Lineare del Contrasto
def adjust_contrast_linear(image, alpha=1.5, beta=0):
    return cv2.convertScaleAbs(image, alpha=alpha, beta=beta)

# Metodo 2: Regolazione Gamma
def adjust_contrast_gamma(image, gamma=1.0):
    inv_gamma = 1.0 / gamma
    table = np.array([(i / 255.0) ** inv_gamma * 255 for i in range(256)]).astype(np.uint8)
    return cv2.LUT(image, table)

def clahe(image, clip_limit=2.0, tile_grid_size=(8, 8)):
    channels = cv2.split(image)
    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_grid_size)
    clahe_channels = [clahe.apply(channel) for channel in channels]
    return cv2.merge(clahe_channels)

def histogram_equalization(image):
    channels = cv2.split(image)
    eq_channels = [cv2.equalizeHist(channel) for channel in channels]
    return cv2.merge(eq_channels)

def clahe_yuv(image, clip_limit=2.0, tile_grid_size=(8, 8)):
    yuv_img = cv2.cvtColor(image, cv2.COLOR_BGR2YUV)
    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_grid_size)
    yuv_img[:, :, 0] = clahe.apply(yuv_img[:, :, 0])
    return cv2.cvtColor(yuv_img, cv2.COLOR_YUV2BGR)

def histogram_equalization_yuv(image):
    yuv_img = cv2.cvtColor(image, cv2.COLOR_BGR2YUV)
    yuv_img[:, :, 0] = cv2.equalizeHist(yuv_img[:, :, 0])
    return cv2.cvtColor(yuv_img, cv2.COLOR_YUV2BGR)

def add_text_to_image(image, text):
    font = cv2.FONT_HERSHEY_SIMPLEX
    font_scale = 1
    color = (255, 255, 255)
    thickness = 2
    position = (10, 50)
    return cv2.putText(image, text, position, font, font_scale, color, thickness, cv2.LINE_AA)

# Genera un'immagine di test
image = cv2.imread(r"\openPyVisionBook\openPyVisionBook\cap3\cap3_6\lena_std.tif")

# Crea immagini con testo
original_with_text = add_text_to_image(image.copy(), "Original")
linear_with_text = add_text_to_image(adjust_contrast_linear(image, alpha=1.5, beta=20).copy(), "Linear Contrast")
gamma_with_text = add_text_to_image(adjust_contrast_gamma(image, gamma=1.2).copy(), "Gamma Adjustment")
clahe_with_text = add_text_to_image(clahe(image).copy(), "CLAHE")
hist_eq_with_text = add_text_to_image(histogram_equalization(image).copy(), "Histogram Equalization")
clahe_yuv_with_text = add_text_to_image(clahe_yuv(image).copy(), "CLAHE YUV")
hist_eq_yuv_with_text = add_text_to_image(histogram_equalization_yuv(image).copy(), "Histogram YUV")

# Crea un mosaico di immagini su due righe
first_row = np.hstack((original_with_text, linear_with_text, clahe_with_text, hist_eq_with_text))
second_row = np.hstack((original_with_text, gamma_with_text, clahe_yuv_with_text, hist_eq_yuv_with_text))
big_image = np.vstack((first_row, second_row))

# Visualizza i risultati
cv2.imshow("Contrast Adjustment", big_image)

# Test delle prestazioni
linear_test = timeit.timeit(lambda: adjust_contrast_linear(image, alpha=1.5, beta=20), number=1000)
gamma_test = timeit.timeit(lambda: adjust_contrast_gamma(image, gamma=1.2), number=1000)
clahe_test = timeit.timeit(lambda: clahe(image), number=1000)
hist_eq_test = timeit.timeit(lambda: histogram_equalization(image), number=1000)
clahe_yuv_test = timeit.timeit(lambda: clahe_yuv(image), number=1000)
hist_eq_yuv_test = timeit.timeit(lambda: histogram_equalization_yuv(image), number=1000)

cv2.waitKey(0)
cv2.destroyAllWindows()

Linear Contrast Adjustment: 0.09 seconds for 1000 iterations = 0.0001 ms per iteration
Gamma Adjustment: 0.11 seconds for 1000 iterations = 0.0001 ms per iteration
CLAHE: 0.93 seconds for 1000 iterations = 0.0009 ms per iteration
Histogram Equalization: 0.56 seconds for 1000 iterations = 0.0006 ms per iteration
CLAHE YUV: 0.56 seconds for 1000 iterations = 0.0006 ms per iteration
Histogram YUV: 0.37 seconds for 1000 iterations = 0.0004 ms per iteration
----

== 3.9 - BASE CLASS EXTENDED

Il passo successivo è aggiungere queste operazioni fondamentali che abbiamo visto alla nostra classe base.

Per il momento creiamo delle variabili che possono essere modificate per attivare o meno un certo effetto:

[source, python]
----
clip_limit = 2.0
tile_grid_size = (8, 8)
gamma = 1.0
isFrameInverted = False
isFrameAutoScreen = False
isFrameCLAHE = False
isFrameHistogramEqualization = False
isFrameCLAHEYUV = False
isFrameHistogramEqualizationYUV = False
----

A questo punto possiamo aggiungere i vari metodi in coda al codice:

[source, python]
----
@staticmethod
def invertFrame(image):
    """
    Inverts the frame colors.
    """
    return cv2.bitwise_not(image)

@staticmethod
def autoScreenFrame(image):
    """
    Automatically creates a screen frame.
    """
    inv1 = cv2.bitwise_not(image)
    mult = cv2.multiply(inv1, inv1, scale=1.0 / 255.0)
    return cv2.bitwise_not(mult).astype(np.uint8)

@staticmethod
def getRGBChannels(frame):
    """
    Returns the RGB channels of a frame.
    """
    return cv2.split(frame)

@staticmethod
def setRGBChannels(channels):
    """
    Sets the RGB channels of a frame.
    """
    return cv2.merge(channels)

@staticmethod
def applyGammaByLut(image, gamma):
    inv_gamma = 1.0 / gamma
    table = np.array([(i / 255.0) ** inv_gamma * 255 for i in range(256)]).astype(np.uint8)
    return cv2.LUT(image, table)

@staticmethod
def applyCLAHE(image, clip_limit=2.0, tile_grid_size=(8, 8)):
    """
    Applies the Contrast Limited Adaptive Histogram Equalization (CLAHE) to the image.
    """
    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_grid_size)
    return clahe.apply(image)

@staticmethod
def applyHistogramEqualization(image):
    """
    Applies the Histogram Equalization to the image.
    """
    return cv2.equalizeHist(image)

@staticmethod
def applyCLAHEYUV(image, clip_limit=2.0, tile_grid_size=(8, 8)):
    """
    Applies the Contrast Limited Adaptive Histogram Equalization (CLAHE) to the Y channel of the YUV image.
    """
    yuv_img = cv2.cvtColor(image, cv2.COLOR_BGR2YUV)
    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_grid_size)
    yuv_img[:, :, 0] = clahe.apply(yuv_img[:, :, 0])
    return cv2.cvtColor(yuv_img, cv2.COLOR_YUV2BGR)

@staticmethod
def applyHistogramEqualizationYUV(image):
    """
    Applies the Histogram Equalization to the Y channel of the YUV image.
    """
    yuv_img = cv2.cvtColor(image, cv2.COLOR_BGR2YUV)
    yuv_img[:, :, 0] = cv2.equalizeHist(yuv_img[:, :, 0])
    return cv2.cvtColor(yuv_img, cv2.COLOR_YUV2BGR)
----

Ora, quello che rimane da fare è stabilire nel `getFrame` se è stata attivata una delle funzioni e restituire il frame modificato.

[source, python]
----
def getFrame(self):
    if self.isFrameInverted:
        self._frame = self.invertFrame(self._frame)
    if self.isFrameAutoScreen:
        self._frame = self.autoScreenFrame(self._frame)
    if self.gamma != 1.0:
        self._frame = self.applyGammaByLut(self._frame, self.gamma)
    if self.isFrameCLAHE:
        self._frame = self.applyCLAHE(self._frame)
    if self.isFrameHistogramEqualization:
        self._frame = self.applyHistogramEqualization(self._frame)
    if self.isFrameCLAHEYUV:
        self._frame = self.applyCLAHEYUV(self._frame)
    if self.isFrameHistogramEqualizationYUV:
        self._frame = self.applyHistogramEqualizationYUV(self._frame)
    return self._frame
----

L'ordine degli effetti è stato scelto considerando che:

* Gli effetti che modificano i colori (come l'inversione o lo screen) devono essere applicati prima delle correzioni di contrasto.
* Gli effetti di correzione del contrasto (CLAHE, equalizzazione dell'istogramma) devono essere applicati per ultimi, per ottimizzare la qualità visiva.

Le operazioni avvengono nella funzione `getFrame` perché di solito non viene modificata nella classe figlia.

Questa architettura ti permette di mantenere la classe base pulita e focalizzata, mentre le classi figlie possono concentrarsi sul compito specifico di generare il frame, sapendo che gli effetti verranno applicati correttamente al momento del rendering.
