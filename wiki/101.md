# OpenPyVision Video Mixer

## Descrizione del Progetto

OpenPyVision è un software di mixing video scritto in Python utilizzando `numpy`, `opencv` e `pyqt6`. L'obiettivo 
del progetto è creare un mixer video facile da usare, con funzionalità avanzate per il compositing live e, in futuro, 
per l'animazione delle telecamere remotate, delle luci e dell'audio.

### La matrice di input
La matrice di input è la parte del mixer dove si stabilisce in quale canale inserire un certo input.

La matrice di input si occupa di video quindi da qui non è possibile specificare gli ingressi audio. Gli ingressi sono 
8 e ovviamente più ingressi comportano un un carico maggiore sul processore. 
 - VideoCapture può acquisire una sorgente video da usb e da pci come ad esempio una camera USB o un periferica 
   di acquisizione tipo black magic ma anche una sorgente rtsp. In pratica tutto quello che può essere digerito 
   da cv2.capture di opencv.
 - Desktop Capture è un desktop capture molto potente, basato sulla libreria dx-cam permette di catturare 
   con uno scarto molto basso un qualunque schermo selezionabile o una porzione di esso. Quindi se si ha uno schermo 
   4k formato da 4 sorgenti video HD è possibile fare lo screen capture di ogni singola porzione e farla diventare un input.
 - Still. E’ possibile caricare delle immagini. L’ideale è che sia dello stesso formato del video quindi 1920x1080 
   altrimenti potrebbe risultare strecciate. E’ la soluzione classica se si ha bisogno di un’immagine di tappo 
   a cui passare in caso di necessità.
 - Video player è un input ancora in anteprima nel senso che opencv in realtà non ha una libreria per gestire l’audio, 
    quindi mettendo in play un video si sente l’audio ma al momento, non avendo ancora inserito il mixer audio non 
    è possibile regolare il volume se non tramite il volume di sistema. Di solito non si usa come input singolo ma
    come parte di una playlist. Una playlist è un input speciale che permette di riprodurre una lista di video o immagini
    in un determinato ordine ed è possibile stabilire il tempo di visualizzazione di ogni elemento o il punto di partenza
    o di fine in caso di video. E' possibile anche stabilire cosa deve succedere alla fine dell'elemento:
        - "cutToNext": taglia al prossimo elemento
         - "fadeToNext": fa un fade al prossimo elemento
         - "fadeToBlack": fa un fade al nero alla fine dell'elemento e poi taglia al prossimo elemento
         - "stop": si ferma e di conseguenza ferma la playlist
    E' possibile anche stabilire se l'elemento si deve ripetere e in che modo:
             - "noLoop": non ripete l'elemento
             - "loopForever": ripete all'infinito l'elemento
             - "loopNTimes": ripete l'elemento un numero di volte stabilito
 - i Generatori di segnale offrono varie possibilità come colore, scacchiera utile per testare gli effetti di keying 
   (ancora in fase sperimentale), generatori di rumore che uso come test di carico del processore ma storicamente 
   sono stati usati per rendere la grafica un po più organica e pareggiare con il video anche perchè come detto, 
 questo è un mixer video ma offre alcune possibilità di compositing, oltre ovviamente ai generatori di sfumature 
 o gradienti che possono essere usati per test e per correggere alcuni difetti.

Ogni input ha una o più opzioni perchè ad esempio esistono vari tipi di rumore, i tipi di input hanno valori di 
iniziazione diversi e quindi è possibile l’opzione che più si abbina al tipo di lavoro che devo fargli fare.

## Struttura del Progetto


###Sincronizzazione

La sincronizzazione è gestita attraverso un oggetto QTimer che emette segnali a ogni 60esimo di secondo.
    
```python

class SynchObject(QObject):
    synch_SIGNAL = pyqtSignal()

    def __init__(self, fps=60, parent=None):
        super().__init__(parent)
        self.fps = fps
        self.syncTimer = QTimer(self)
        self.syncTimer.timeout.connect(self.sync)
        self.syncTimer.start(1000 // fps)

    def sync(self):
        self.synch_SIGNAL.emit()
```

## Input 

### BaseClass

La classe `BaseClass` è una classe base per tutti gli input. È una sottoclasse di `QObject`, quindi può essere 
usata con i segnali e gli slot, ma non ha un'interfaccia grafica. Ha bisogno che gli venga passato un oggetto
`SynchObject` per sincronizzare i frame. La classe ha un metodo `getFrame` che restituisce un frame.



```python
class BaseClass(QObject):
    def __init__(self, synchObject, resolution=QSize(1920, 1080)):
        # Inizializzazione della classe

    def getFrame(self):
        # Restituisce un frame
```

### VideoCapture

La classe VideoCapture è una sottoclasse di BaseClass e rappresenta un'entità che cattura i frame da una sorgente video
usa la libreria OpenCV per catturare i frame da una webcam o da una scheda di acquisizione. OpenCV non ha un sistema per
ottenere il nome della periferica, quindi si usa ffmpeg per ottenere le informazioni sui dispositivi. Queste informazioni 
vengono reperite usando la classe DeviceUpdater, che è un thread che esegue un comando ffmpeg per ottenere le informazioni
sui dispositivi audio e video disponibili. Se il dispositivo è noto, perchè ad esempio è stato già selezionato da una combo
box, tipo quella di matrixWidget si può passare il dizionario altrimenti il dizionario viene calcolato automaticamente.

Il dizionario serve per sapere se il dispositivo è una webcam o una scheda di acquisizione. Mentre il dispositivo di 
acquisizione ha generalmente un'interfaccia grafica creata dal produttore per impostare i parametri di acquisizione,
la web cam non li ha. Se la webcam è un pò datata, potrebbe fra l'altro non supportare l'acquisizione con con driver
diversi da DShow (quindi non ha una latenza ottimizzata). In alternativa si può usare forceDShow=True per forzare l'uso 
di Dshow e saltare la ricerca dei dispositivi.

La classe DeviceUpdater è un thread che esegue un comando ffmpeg per ottenere le informazioni sui
dispositivi audio e video disponibili. Open cv non ha un sistema per ottenere informazioni dai dispositivi audio e video. 
Quello che si può fare quindi è usare ffmpeg per ottenere queste informazioni. In opencv bisogna inserire banalmente 
il numero del dispositivo per poterlo utilizzare, quindi si può creare un elenco di dispositivi audio e video 
disponibili e passare il numero del dispositivo selezionato a opencv.  

### DesktopCapture

La classe ScreenCapture è una sottoclasse di BaseClass e gestisce la cattura dello schermo utilizzando la libreria 
dxcam. La classe cattura i frame dello schermo a un FPS target e li ridimensiona se necessario.

Nell'inizializzazione della classe, si inizializza la camera per catturare lo schermo. Se la cattura dello schermo
fallisce, si prova a catturare lo schermo di default. La funzione checkSize controlla se il frame deve essere ridimensionato.
La funzione capture_frame cattura un frame dallo schermo e la funzione getFrame restituisce il frame processato.

### Still

La classe Still è una sottoclasse di BaseClass e rappresenta un'entità che cattura un'immagine statica. Fa comodo nei casi
in cui si debba passare un'immagine di tappo o un'immagine statica di qualsiasi tipo. Non ha una funzione di controllo
della risoluzione perchè si assume che l'immagine sia già della risoluzione corretta.

### VideoPlayer

La classe VideoPlayer è una sottoclasse di BaseClass e rappresenta un'entità che riproduce un video. Usa la libreria
OpenCV per riprodurre un video e soundDevice per l'audio. Al momento l'audio non è regolabile. 
La classe ha un metodo `play` che riproduce il video e un metodo `stop` che ferma la riproduzione.

### playlist
E' un input speciale che permette di riprodurre una lista di video o immagini in un determinato ordine ed è possibile
stabilire il tempo di visualizzazione di ogni elemento o il punto di partenza o di fine in caso di video. 
E' anche possibile stabilire cosa deve succedere alla fine dell'elemento: 

 - "cutToNext": taglia al prossimo elemento
 - "fadeToNext": fa un fade al prossimo elemento
 - "fadeToBlack": fa un fade al nero alla fine dell'elemento e poi taglia al prossimo elemento
 - "stop": si ferma e di conseguenza ferma la playlist

E' possibile anche stabilire se l'elemento si deve ripetere e in che modo:
    
 - "noLoop": non ripete l'elemento
 - "loopForever": ripete all'infinito l'elemento
 - "loopNTimes": ripete l'elemento un numero di volte stabilito
 - "loopToNext": ripete l'elemento e poi taglia al prossimo elemento
   


## MIX BUS
Il **MixBus** è una componente fondamentale del nostro sistema di mixing video, responsabile della creazione del clean feed, 
ovvero il mix tra il segnale di preview e quello di program. Questo permette di ottenere una transizione fluida e 
professionale tra diverse sorgenti video. È possibile applicare diversi effetti di transizione come il fade, il dissolve, 
il wipe e lo stinger.


